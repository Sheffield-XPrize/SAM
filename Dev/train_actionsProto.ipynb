{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "argv=['','/home/daniel/SAM_Data_Models/Data/Actions2', '/home/daniel/SAM_Data_Models/Models/', 'train_actions2', 'new','return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from SAM.SAM_Drivers import SAMDriver_AR\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import readline\n",
    "import warnings\n",
    "import GPy\n",
    "from SAM.SAM_Core import SAMCore\n",
    "from SAM.SAM_Core import SAMDriver\n",
    "import pylab as pb\n",
    "import sys \n",
    "from sys import executable\n",
    "import subprocess\n",
    "from subprocess import Popen, PIPE\n",
    "import pickle\n",
    "import os\n",
    "from os import listdir, walk, system\n",
    "from os.path import isfile, join, isdir\n",
    "import time\n",
    "import operator\n",
    "import numpy\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "np.set_printoptions(threshold=numpy.nan)\n",
    "import datetime\n",
    "import yarp\n",
    "import copy\n",
    "from itertools import combinations \n",
    "from ConfigParser import SafeConfigParser\n",
    "from scipy.spatial import distance\n",
    "from numpy.linalg import inv\n",
    "import math\n",
    "import ipyparallel as ipp\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testFunc(data, lab):\n",
    "        d = mySAMpy.testing(data, False)\n",
    "        if(lab == d[0]):\n",
    "            result = True\n",
    "        else:\n",
    "            result = False\n",
    "        print 'Actual  ' + str(lab).ljust(11) + '  Model:  ' + str(d[0]).ljust(11) + '  with ' + str(d[1])[:6] + ' confidence: ' + str(result) + '\\n'\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yarpRunning = False\n",
    "dataPath = argv[1]\n",
    "modelPath = argv[2]\n",
    "trainName = argv[3]\n",
    "mode = argv[4]\n",
    "if(len(argv > 5)):\n",
    "    returnMode = True\n",
    "singleModel = False\n",
    "\n",
    "#participantList is extracted from number of subdirectories of dataPath\n",
    "participantList = [f for f in listdir(dataPath) if isdir(join(dataPath, f))]\n",
    "if (len(participantList) < 1):\n",
    "    singleModel = True\n",
    "\n",
    "off = 17\n",
    "print '-------------------'\n",
    "print 'Training Settings:'\n",
    "print\n",
    "print 'Data Path: '.ljust(off), dataPath\n",
    "print 'Model Path: '.ljust(off),modelPath\n",
    "print 'Participants: '.ljust(off),participantList\n",
    "print 'Model Root Name: '.ljust(off), trainName\n",
    "print 'Training Mode:'.ljust(off), mode\n",
    "print '-------------------'\n",
    "print 'Loading Parameters...'\n",
    "print\n",
    "\n",
    "try:\n",
    "    parser = SafeConfigParser()\n",
    "    found = parser.read(dataPath + \"/config.ini\")\n",
    "\n",
    "    if(parser.has_option(trainName, 'update_mode')):\n",
    "        modeConfig = parser.get(trainName, 'update_mode') \n",
    "    else:\n",
    "        modeConfig = 'update'\n",
    "except IOError:\n",
    "    pass\n",
    "\n",
    "if(mode == 'new' or modeConfig == 'new' or '.pickle' not in modelPath): #or update but no .pickle\n",
    "    print 'Loading training parameters from: \\n ', '\\t' + dataPath + \"/config.ini\"\n",
    "    try:\n",
    "        parser = SafeConfigParser()\n",
    "        found = parser.read(dataPath + \"/config.ini\")\n",
    "\n",
    "        #load parameters from config file\n",
    "        if(parser.has_option(trainName, 'ignoreLabels')):\n",
    "            ignoreLabels = parser.get(trainName, 'ignoreLabels').split(',')\n",
    "        else:\n",
    "            ignoreLabels = ['agent_entry','agent_exit','no_agent']\n",
    "        \n",
    "        if(parser.has_option(trainName, 'actionsAllowedList')):\n",
    "            actionsAllowedList = parser.get(trainName, 'actionsAllowedList').split(',')\n",
    "        else:\n",
    "            actionsAllowedList = ['lift_object','pull_object','push_object','drop_object','carry_object']\n",
    "        \n",
    "        if(parser.has_option(trainName, 'percentContactThreshold')):\n",
    "            percentContactThreshold = float(parser.get(trainName, 'percentContactThreshold'))\n",
    "        else:\n",
    "            percentContactThreshold = 98.0\n",
    "        \n",
    "        if(parser.has_option(trainName, 'jointMu')):\n",
    "            jointMu = float(parser.get(trainName, 'jointMu'))\n",
    "        else:\n",
    "            jointMu = 0\n",
    "            \n",
    "        if(parser.has_option(trainName, 'jointSig')):\n",
    "            jointSig = float(parser.get(trainName, 'jointSig'))\n",
    "        else:\n",
    "            jointSig = 0.0000001\n",
    "\n",
    "        if(parser.has_option(trainName, 'featuresToUse')):\n",
    "            featuresToUse = parser.get(trainName, 'featuresToUse').split(',')\n",
    "        else:\n",
    "            featuresToUse = ['contact','selfMovementLabelK']\n",
    "        \n",
    "        if(parser.has_option(trainName, 'ignoreParts')):\n",
    "            ignoreParts = parser.get(trainName, 'ignoreParts').split(',')\n",
    "        else:\n",
    "            ignoreParts = ['partner']\n",
    "            \n",
    "        if(parser.has_option(trainName, 'compressData')):\n",
    "            compressData = parser.get(trainName, 'compressData')\n",
    "        else:\n",
    "            compressData = True\n",
    "        \n",
    "        if(parser.has_option(trainName, 'featuresToCompress')):\n",
    "            featuresToCompress = parser.get(trainName, 'featuresToCompress').split(',')\n",
    "        else:\n",
    "            featuresToCompress = ['selfMovementLabelK']\n",
    "\n",
    "        if(parser.has_option(trainName, 'experiment_number')):\n",
    "            experiment_number = int(parser.get(trainName, 'experiment_number'))\n",
    "        elif('.pickle' in modelPath):\n",
    "            experiment_number = int(modelPath.split('__')[-2].replace('exp','')) + 1\n",
    "        else:\n",
    "            experiment_number = 0\n",
    "\n",
    "        if(parser.has_option(trainName, 'ratioData')):\n",
    "            ratioData = int(parser.get(trainName, 'ratioData'))\n",
    "        else:\n",
    "            ratioData = 50\n",
    "        \n",
    "        if(parser.has_option(trainName, 'maxNumItems')):\n",
    "            maxNumItems = int(parser.get(trainName, 'maxNumItems'))\n",
    "        else:\n",
    "            maxNumItems = 20000\n",
    "\n",
    "        if(parser.has_option(trainName, 'angleThreshold')):\n",
    "            angThresh = float(parser.get(trainName, 'angleThreshold'))\n",
    "        else:\n",
    "            angThresh = 0.01\n",
    "\n",
    "        if(parser.has_option(trainName, 'deltaDistanceThreshold')):\n",
    "            deltaDistanceThreshold = float(parser.get(trainName, 'deltaDistanceThreshold'))\n",
    "        else:\n",
    "            deltaDistanceThreshold = 0.01\n",
    "\n",
    "        if(parser.has_option(trainName, 'contactThreshold')):\n",
    "            contThresh = float(parser.get(trainName, 'contactThreshold'))\n",
    "        else:\n",
    "            contThresh = 0.01\n",
    "\n",
    "        if(parser.has_option(trainName, 'model_type')):\n",
    "            model_type = parser.get(trainName, 'model_type')\n",
    "        else:\n",
    "            model_type = 'mrd'\n",
    "\n",
    "        if(parser.has_option(trainName, 'model_num_inducing')):\n",
    "            model_num_inducing = int(parser.get(trainName, 'model_num_inducing'))\n",
    "        else:\n",
    "            model_num_inducing = 30\n",
    "\n",
    "        if(parser.has_option(trainName, 'model_num_iterations')):\n",
    "            model_num_iterations = int(parser.get(trainName, 'model_num_iterations'))\n",
    "        else:\n",
    "            model_num_iterations = 700\n",
    "\n",
    "        if(parser.has_option(trainName, 'Q')):\n",
    "            Quser = int(parser.get(trainName, 'Q'))\n",
    "        else:\n",
    "            Quser = 2\n",
    "\n",
    "        if(parser.has_option(trainName, 'model_init_iterations')):\n",
    "            model_init_iterations = int(parser.get(trainName, 'model_init_iterations'))\n",
    "        else:\n",
    "            model_init_iterations = 2000\n",
    "\n",
    "        if(parser.has_option(trainName, 'kernelString')):\n",
    "            kernelString = parser.get(trainName, 'kernelString')\n",
    "        else:\n",
    "            kernelString = \"GPy.kern.RBF(Q, ARD=False) + GPy.kern.Bias(Q) + GPy.kern.White(Q)\"\n",
    "\n",
    "    except IOError:\n",
    "        pass\n",
    "else:\n",
    "    print 'Loading parameters from: \\n ','\\t' + modelPath\n",
    "    try:\n",
    "        parser = SafeConfigParser()\n",
    "        found = parser.read(dataPath + \"/config.ini\")\n",
    "\n",
    "        #load parameters from config file\n",
    "        if(parser.has_option(trainName, 'experiment_number')):\n",
    "            experiment_number = int(parser.get(trainName, 'experiment_number'))\n",
    "        else:\n",
    "            experiment_number = int(modelPath.split('__')[-2].replace('exp',''))\n",
    "    except IOError:\n",
    "        pass\n",
    "\n",
    "    modelPickle = pickle.load(open(modelPath ,'rb'))\n",
    "    ignoreLabels = modelPickle['ignoreLabels']\n",
    "    ignoreParts = modelPickle['ignoreParts']\n",
    "    angThresh = modelPickle(['angleThreshold'])\n",
    "    distThresh = modelPickle(['distanceThreshold'])\n",
    "    contThresh = modelPickle(['contactThreshold'])\n",
    "    Quser = modelPickle['Quser']\n",
    "    ratioData = modelPickle['percentTestData']\n",
    "    model_type = modelPickle['model_type']\n",
    "    model_num_inducing = modelPickle['num_inducing']\n",
    "    model_init_iterations = modelPickle['model_init_iterations']\n",
    "    model_num_iterations = modelPickle['model_num_iterations']\n",
    "    kernelString = modelPickle['kernelString']\n",
    "    \n",
    "# # Creates a SAMpy object\n",
    "mySAMpy = SAMDriver_AR.SAMDriver_AR(False)\n",
    "\n",
    "if('.pickle' in modelPath):\n",
    "    fname = '/'.join(modelPath.split('/')[:-1]) + '/' + dataPath.split('/')[-1] + '__' + trainName + '__' +  model_type + '__exp' + str(experiment_number)\n",
    "else:\n",
    "    fname = modelPath + dataPath.split('/')[-1] + '__' + trainName + '__' +  model_type + '__exp' + str(experiment_number) #+ '.pickle'\n",
    "\n",
    "print 'Full model name: \\n', '\\t' + fname\n",
    "print '-------------------'\n",
    "print\n",
    "\n",
    "save_model = False\n",
    "economy_save = True\n",
    "visualise_output = False\n",
    "test_mode = True\n",
    "mySAMpy.percentContactThreshold = percentContactThreshold\n",
    "mySAMpy.contactThreshold = contThresh\n",
    "mySAMpy.deltaDistanceThreshold = deltaDistanceThreshold\n",
    "mySAMpy.angleThreshold = angThresh\n",
    "mySAMpy.verbose = True\n",
    "mySAMpy.ignoreLabels = ignoreLabels\n",
    "mySAMpy.ignoreParts = ignoreParts\n",
    "mySAMpy.actionsAllowedList = actionsAllowedList\n",
    "mySAMpy.compressData = compressData\n",
    "mySAMpy.featuresToUse = featuresToUse\n",
    "mySAMpy.featuresToCompress = featuresToCompress\n",
    "mySAMpy.jointMu = jointMu\n",
    "mySAMpy.jointSig = jointSig\n",
    "mySAMpy.maxNumItems = maxNumItems\n",
    "\n",
    "# # Reading action data\n",
    "mySAMpy.readData(dataPath, participantList)\n",
    "\n",
    "minData = mySAMpy.Y.shape[0]\n",
    "\n",
    "print mySAMpy.Y.shape\n",
    "print 'minData = ' + str(minData)\n",
    "print 'ratioData = ' + str(ratioData)\n",
    "Ntr = ratioData\n",
    "mySAMpy.Quser = Quser\n",
    "\n",
    "[Yall,Lall,YtestAll,LtestAll] = mySAMpy.prepareData(model_type, Ntr, randSeed=experiment_number)\n",
    "mySAMpy.training(model_num_inducing, model_num_iterations, model_init_iterations, fname, save_model, economy_save, keepIfPresent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if visualise_output: \n",
    "    ax = mySAMpy.SAMObject.visualise()\n",
    "    visualiseInfo=dict()\n",
    "    visualiseInfo['ax']=ax\n",
    "else:\n",
    "    visualiseInfo=None\n",
    "\n",
    "c = ipp.Client()\n",
    "dview = c[:]\n",
    "\n",
    "with dview.sync_imports():\n",
    "    from SAM.SAM_Drivers import SAMDriver_AR\n",
    "\n",
    "dview.push({'mySAMpy':mySAMpy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ss = []\n",
    "sstest = []\n",
    "print\n",
    "off1 = 11\n",
    "off2 = 8\n",
    "\n",
    "# allCount = Yall.shape[0]\n",
    "# factor = 40\n",
    "# numItems = int(allCount/factor)\n",
    "cmSize = len(mySAMpy.textLabels)\n",
    "confMatrix = np.zeros((cmSize, cmSize))\n",
    "numItems = Yall.shape[0]\n",
    "\n",
    "off3 = len(str(numItems))\n",
    "\n",
    "print 'estimated time: ' + str(numItems/60) + 'mins for ' + str(numItems) + ' items'\n",
    "#format training data\n",
    "\n",
    "yTrainingData = mySAMpy.formatDataFunc(Yall)\n",
    "YsampleIdx = [ i for i in sorted(random.sample(xrange(len(yTrainingData)),numItems)) ]\n",
    "\n",
    "Ysample = [yTrainingData[i] for i in YsampleIdx]\n",
    "Lsample = [mySAMpy.textLabels[int(Lall[i])] for i in YsampleIdx]\n",
    "\n",
    "%time syn = dview.map_async(testFunc, Ysample, Lsample)\n",
    "mySAMpy.wait_watching_stdout(syn, dt=1, truncate=1000)\n",
    "ret = syn.get()\n",
    "# clear_output()\n",
    "for i in range(len(ret)):\n",
    "\n",
    "    currLabel = Lsample[i]\n",
    "\n",
    "    if(currLabel == ret[i][0]):\n",
    "        result = True\n",
    "    else:\n",
    "        result = False\n",
    "    print str(i).rjust(off3) + '/' + str(numItems) + ' Truth: ' + currLabel.ljust(off1) + ' Model: ' + ret[i][0].ljust(off1) + ' with ' + str(1-ret[i][1])[:6].ljust(off2) + ' confidence: ' + str(result)\n",
    "    confMatrix[mySAMpy.textLabels.index(currLabel),mySAMpy.textLabels.index(ret[i][0])] += 1\n",
    "    ss.append(ret[i][0])\n",
    "\n",
    "confMatLabels = copy.deepcopy(mySAMpy.textLabels)\n",
    "#confMatLabels.sort()\n",
    "\n",
    "h = confusion_matrix(Lsample, ss)\n",
    "total = h.astype(np.float).sum(axis=1)\n",
    "normConf = copy.deepcopy(h)\n",
    "normConf = normConf.astype(np.float)\n",
    "\n",
    "for l in range(h.shape[0]):\n",
    "    normConf[l,:] = normConf[l,:].astype(np.float)*100/total[l].astype(np.float)\n",
    "\n",
    "print normConf\n",
    "\n",
    "mySAMpy.plot_confusion_matrix(normConf, confMatLabels)\n",
    "\n",
    "percCorect = 100*np.diag(h.astype(np.float)).sum()/numItems\n",
    "\n",
    "print str(percCorect)[:5].ljust(7) + \"% correct for training data\"\n",
    "print\n",
    "for i in range(cmSize):\n",
    "    for j in range(cmSize):\n",
    "        print str(normConf[i,j])[:5].ljust(7) + '% of ' + str(mySAMpy.textLabels[i]) + ' classified as ' + str(mySAMpy.textLabels[j])\n",
    "    print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# allCount = Yall.shape[0]\n",
    "# factor = 40\n",
    "# numItems = int(allCount/factor)\n",
    "cmSize = len(mySAMpy.textLabels)\n",
    "confMatrixTest = np.zeros((cmSize, cmSize))\n",
    "numItems = YtestAll.shape[0]\n",
    "\n",
    "off3 = len(str(numItems))\n",
    "\n",
    "print 'estimated time: ' + str(numItems/60) + 'mins for ' + str(numItems) + ' items'\n",
    "#format training data\n",
    "\n",
    "yTrainingData = mySAMpy.formatDataFunc(YtestAll)\n",
    "YsampleIdx = [ i for i in sorted(random.sample(xrange(len(yTrainingData)),numItems)) ]\n",
    "\n",
    "Ysample = [yTrainingData[i] for i in YsampleIdx]\n",
    "Lsample = [mySAMpy.textLabels[int(LtestAll[i])] for i in YsampleIdx]\n",
    "\n",
    "%time syn = dview.map_async(testFunc, Ysample, Lsample)\n",
    "mySAMpy.wait_watching_stdout(syn, dt=1, truncate=1000)\n",
    "ret = syn.get()\n",
    "clear_output()\n",
    "for i in range(len(ret)):\n",
    "\n",
    "    currLabel = Lsample[i]\n",
    "\n",
    "    if(currLabel == ret[i][0]):\n",
    "        result = True\n",
    "    else:\n",
    "        result = False\n",
    "    print str(i).rjust(off3) + '/' + str(numItems) + ' Truth: ' + currLabel.ljust(off1) + ' Model: ' + ret[i][0].ljust(off1) + ' with ' + str(1-ret[i][1])[:6].ljust(off2) + ' confidence: ' + str(result)\n",
    "    sstest.append(ret[i][0])\n",
    "\n",
    "confMatrixTest = confusion_matrix(Lsample, sstest)\n",
    "total = confMatrixTest.astype(np.float).sum(axis=1)\n",
    "normConfTest = copy.deepcopy(confMatrixTest)\n",
    "normConfTest = normConfTest.astype(np.float)\n",
    "\n",
    "for l in range(confMatrixTest.shape[0]):\n",
    "    normConfTest[l,:] = normConfTest[l,:].astype(np.float)*100/total[l].astype(np.float)\n",
    "\n",
    "print normConfTest\n",
    "\n",
    "mySAMpy.plot_confusion_matrix(normConfTest, confMatLabels)\n",
    "\n",
    "percCorect = 100*np.diag(confMatrixTest.astype(np.float)).sum()/numItems \n",
    "\n",
    "print str(percCorect)[:5].ljust(7) + \"% correct for testing data\"\n",
    "print\n",
    "for i in range(cmSize):\n",
    "    for j in range(cmSize):\n",
    "        print str(normConfTest[i,j])[:5].ljust(7)  + '% of ' + str(mySAMpy.textLabels[i]) + ' classified as ' + str(mySAMpy.textLabels[j])\n",
    "    print\n",
    "\n",
    "print\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if(returnMode):\n",
    "    return [normConf,normConfTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
